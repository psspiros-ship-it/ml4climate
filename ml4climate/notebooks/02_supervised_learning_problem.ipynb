{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eb8c31b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Supervised Learning Problem\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/git/https%3A%2F%2Fgitlab.in2p3.fr%2Fenergy4climate%2Fpublic%2Feducation%2Fmachine_learning_for_climate_and_energy/master?filepath=book%2Fnotebooks%2F02_supervised_learning_problem.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a485dc1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>Prerequisites</b>\n",
    "    \n",
    "- [Elements of Probability Theory](appendix_elements_of_probability_theory.ipynb)  \n",
    "- Define *supervised* and *unsupervised* learning\n",
    "- Give the difference between *qualitative* and *quantitative* variables and define of *regression* and *classification*\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8790b2ae",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Learning Outcomes</b>\n",
    "    \n",
    "- Define a supervised learning problem\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d2a305",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example: Home Heating\n",
    "\n",
    "<img alt=\"Thermostat\" src=\"images/erik-mclean-fSLI8RdCdyk-unsplash.jpg\" width=500  style=\"float:right\">\n",
    "\n",
    "When its cold in my accommodation, I heat it.\n",
    "\n",
    "$\\rightarrow$ I suspect a relationship between the energy I consume to heat my accommodation and the outdoor temperature, although other factors may also play a role."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dffe444",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How to *predict* how much energy I consume on average depending on the outdoor temperature ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d265d6fa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Three Different Approaches to Home-Heating Modeling\n",
    "\n",
    "| Process-based | Expert-based | *Statistical* |\n",
    "| --- | --- | --- |\n",
    "| Use some approximation of the heat equation in my accommodation given heat sources (radiators) and sinks (outdoor). | A thermal engineer diagnoses my accommodation based on his/her knowledge and/or on conventions. | Use energy-consumption and outdoor-temperature data to estimate parameters of a model. |\n",
    "| <img alt=\"Building Energy Model\" src=\"images/Heat_losses_of_the_building-fr.svg\" width=\"180\"> | <img alt=\"DPE\" src=\"images/Diagnostic_de_performance_énergétique.svg\" width=\"150\"> | <img alt=\"Statistical Model\" src=\"images/linear_ols.svg\" width=\"280\"> |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ad72db",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Supervised Learning Objective\n",
    "\n",
    "To define a supervised-learning problem we need:\n",
    "\n",
    "- an *input* vector $\\boldsymbol{X}$ of $X_1, \\ldots, X_p$ input variables, or *features* and\n",
    "- an *output* or *target* variable $Y$ used for supervision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b72df4e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "**Supervised Learning Objective**\n",
    "<br>\n",
    "Construct the \"best\" prediction rule to predict $Y$ based on some *training data*: $(\\boldsymbol{x}_i, y_i), i = 1, \\ldots N$. \n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf930c0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Supervised-Learning Flow: Fit and Predict\n",
    "\n",
    "<img alt=\"Pipeline Fit\" src=\"images/api_diagram-predictor.fit.svg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc234b6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img alt=\"Pipeline Fit\" src=\"images/api_diagram-predictor.predict.svg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fede6e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Supervised-Learning Flow: Transform-Fit and Transform-Predict\n",
    "\n",
    "<img alt=\"Pipeline Fit\" src=\"images/api_diagram-pipeline.fit.svg\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7104da",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img alt=\"Pipeline Fit\" src=\"images/api_diagram-pipeline.predict.svg\" width=\"860\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb097aee",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The $i$th *observation* of $X_j$ in the *sample* is given by the element $x_{ij}$ of the $N\\times p$ *input-data matrix* $\\mathbf{X}$.\n",
    "\n",
    "The $i$th observation of $y$ is given by the element $y_i$ of the $N \\times 1$ *output-data vector* $\\mathbf{y}$.\n",
    "\n",
    "> ***Question***\n",
    "> - Recall the unbiased estimates of the sample mean $\\bar{y}$ and the sample variance $s_Y^2$  of the random variable $Y$ for some data $y_i, 1 \\le i \\le N$.\n",
    "> - Recall the unbiased estimate of the sample covariance $q_{X, Y}$ between $X$ and $Y$ for $(x_i, y_i), 1 \\le i \\le N$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30513405",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Regression / Classification\n",
    "\n",
    "| Regression | Classification |\n",
    "| ------------------------------------- | --------------------------------------- |\n",
    "| $Y$ is quantitative | $Y$ is qualitative |\n",
    "| <img src=\"images/artur-solarz-hihmzc-TToc-unsplash.jpg\" width=\"350\"> | <img src=\"images/supervised.png\" width=\"300\"> |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a34685",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example: Electricity Consumption Dependence on Temperature\n",
    "\n",
    "- *Raw input*: temperature averaged over an administrative region of metropolitan France\n",
    "- *Target*: regional electricity consumption\n",
    "\n",
    "Let's first get familiar with the raw input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9e9941c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Set data directory\n",
    "data_dir = Path('data')\n",
    "\n",
    "# Set keyword arguments for pd.read_csv\n",
    "kwargs_read_csv = dict(header=0, index_col=0, parse_dates=True)\n",
    "\n",
    "# Set first and last years\n",
    "FIRST_YEAR = 2014\n",
    "LAST_YEAR = 2021\n",
    "\n",
    "# Define file path\n",
    "filename = 'surface_temperature_merra2_{}-{}.csv'.format(\n",
    "    FIRST_YEAR, LAST_YEAR)\n",
    "filepath = Path(data_dir, filename)\n",
    "\n",
    "# Read hourly temperature data averaged over each region\n",
    "df_temp = pd.read_csv(filepath, **kwargs_read_csv).resample('D').mean()\n",
    "temp_lim = [-5, 30]\n",
    "label_temp = 'Temperature (°C)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa7aa559",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Scatter plot of demand versus temperature\n",
    "def plot_temp(region_name=df_temp.columns[0], year=FIRST_YEAR):\n",
    "    df = df_temp[[region_name]].loc[str(year)]\n",
    "    df.columns = [label_temp]\n",
    "    nt = df.shape[0]\n",
    "    std = float(df.std(0).iloc[0])\n",
    "    mean = pd.Series(df[label_temp].mean(), index=df.index)\n",
    "    df_std = pd.DataFrame(\n",
    "        {'low': mean - std, 'high': mean + std}, index=df.index)\n",
    "    cdf = pd.DataFrame(index=df.sort_values(by=label_temp).values[:, 0],\n",
    "                       data=(np.arange(nt)[:, None] + 1) / nt)\n",
    "    cdf.index.name = label_temp\n",
    "    cdf.columns = ['Probability']\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3)\n",
    "    fig.set_figwidth(15)\n",
    "\n",
    "    pts = df.plot(ax=axes[0],ylim=temp_lim, title='Time series, Mean, ± 1 STD')\n",
    "    pts.hlines(df[label_temp].mean(), xmin=df.index[0], xmax=df.index[-1], linestyles='dashed')\n",
    "    pts.fill_between(df_std.index.values, df_std.low, df_std.high, alpha=.2)\n",
    "\n",
    "    pcdf = cdf.plot(ax=axes[1],xlim=temp_lim, ylim=[0, 1], title='Cumulative Distrib. Func.')\n",
    "    pcdf.vlines(df[label_temp].mean(), ymin=0, ymax=1, linestyles='dashed')\n",
    "\n",
    "    \n",
    "    pkde = df.plot.kde(ax=axes[2],xlim=temp_lim, title='Probability Density Func.')\n",
    "    ylim3 = pkde.get_ylim()\n",
    "    pkde.vlines(df[label_temp].mean(), ymin=0, ymax=ylim3[1], linestyles='dashed')\n",
    "    pkde.set_ylim([0, ylim3[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4028e1ca",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c35e79b79e4180bcff1312799ac431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='region_name', options=('Grand Est', 'Nouvelle-Aquitaine', 'Auvergn…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_temp(region_name='Grand Est', year=2014)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show\n",
    "from ipywidgets import interact\n",
    "interact(plot_temp,region_name=df_temp.columns, year=range(FIRST_YEAR, LAST_YEAR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451b43ed",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> ***Question***\n",
    "> - Describe how the mean and the standard deviation of the time series above depend on the region and on the year.\n",
    "> - How do these dependencies show on the cumulative distribution and probability density functions?\n",
    "\n",
    "Now let's compare the target data with the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f503cb99",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Read hourly demand data summed over each region\n",
    "filename = 'reseaux_energies_demand_demand.csv'\n",
    "filepath = Path(data_dir, filename)\n",
    "df_dem = pd.read_csv(filepath, **kwargs_read_csv).resample('D').sum()\n",
    "label_dem = 'Demand (MWh)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9394c735",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Scatter plot of demand versus temperature\n",
    "def scatter_temp_dem(region_name=df_temp.columns[0], year=FIRST_YEAR):\n",
    "    df = pd.concat([df_temp[region_name], df_dem[region_name]],\n",
    "                   axis='columns', ignore_index=True).loc[str(year)]\n",
    "    df.columns = [label_temp, label_dem]\n",
    "    df.plot.scatter(x=label_temp, y=label_dem, xlim=[-5, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a212e73",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2204afe0af8a409d8cf4c3d435c75c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='region_name', options=('Grand Est', 'Nouvelle-Aquitaine', 'Auvergn…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.scatter_temp_dem(region_name='Grand Est', year=2014)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show\n",
    "interact(scatter_temp_dem,region_name=df_temp.columns, year=range(FIRST_YEAR, LAST_YEAR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b783ee9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Supervised Learning Problem Definition\n",
    "\n",
    "Given the output $Y$,\n",
    "\n",
    "- define features $\\boldsymbol{X} = (X_1, \\ldots, X_p)$ based on (transformed) raw inputs\n",
    "- define model by a function $f: \\boldsymbol{X} \\mapsto f(\\boldsymbol{X})$\n",
    "- define *loss function* $L(Y, f(\\boldsymbol{X}))$\n",
    "- choose a training set $(\\boldsymbol{x}_i, y_i), i = 1, \\ldots, N$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578435ca",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Example of model (linear): $f_{\\boldsymbol{\\beta}}(\\boldsymbol{X}) = \\beta_0 + \\sum_{j = 1}^p X_j \\beta_j$\n",
    "\n",
    "Example of loss (squared error): $L(Y, f(\\boldsymbol{X})) = \\left(Y - f(\\boldsymbol{X})\\right)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a167c4e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>Assumption</b>\n",
    "    \n",
    "All random variables and random vectors have finite variance and have densities (they are absolutely continuous with respect to the Lebesgue measure).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6bba45",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "**Expected Prediction Error**\n",
    "<br>\n",
    "For some model function $f$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathrm{EPE}(f) = \\mathbb{E}(L(Y, f(\\boldsymbol{X})))\n",
    "= \\int L(y, f(\\boldsymbol{x})) \\rho_{\\boldsymbol{X}, Y}(\\boldsymbol{x}, y) d\\boldsymbol{x} dy,\n",
    "\\end{equation}\n",
    "\n",
    "where $\\rho_{\\boldsymbol{X}, Y}$ is the joint probability density of $\\boldsymbol{X}$ and $Y$.\n",
    "<hr>\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Supervised Learning Objective (Concrete)**\n",
    "<br>\n",
    "Find $\\hat{f}$ over all possible $f$ such that the EPE is minimized.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3d5baf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Estimating the EPE\n",
    "\n",
    "If the law of large numbers applies and for a fixed number $N$ of training data and an increasing number $N' - N$ of new (test) data,\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{1}{N'} \\sum_{i = 1}^{N'} L(y_i, f(\\boldsymbol{x}_i)) \\underset{N' \\to \\infty}{\\to} \\mathrm{EPE}(f).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96217dc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "From the law of total expectation, we have that\n",
    "\n",
    "\\begin{align}\n",
    "\\mathrm{EPE}(f)\n",
    "&= \\mathbb{E}(\\mathbb{E}[L(Y, f(X)) | X])\\\\\n",
    "&= \\int L(y, f(x)) \\rho_{Y | X = x}(y) \\rho_X(x)dy dx,\n",
    "\\end{align}\n",
    "\n",
    "where $\\rho_X$ is the probability density of $X$ and $\\rho_{Y | X}$ is the conditional probability density of $Y$ knowing $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83dbbb3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The EPE can thus be interpreted as averaging over the inputs the prediction error for any input and can be minimized pointwise:\n",
    "\n",
    "\\begin{equation}\n",
    "f(x) = \\mathrm{argmin}_c \\mathbb{E}\\left[L(Y, c) | X = x\\right].\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848dd002",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">    \n",
    "    <b>Remark</b>\n",
    "    \n",
    "    \n",
    "Here, $f$ is the best possible model among all possible functions of $x$.\n",
    "\n",
    "This is a theoretical notion.\n",
    "    \n",
    "In practice, we look for an $f$ in a set of models which is smaller than the set of all possible functions of $x$ (e.g. a linear model).\n",
    "    \n",
    "In that case, the model must be trained over all points in a relatively large sample so that the minimization cannot in general be done pointwise. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941854e3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Case of Squared Error Loss\n",
    "\n",
    "The EPE using the squared error loss is\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathrm{EPE}(f) = \\mathbb{E}((Y - f(X))^2).\n",
    "\\end{equation}\n",
    "\n",
    "Then\n",
    "\\begin{equation}\n",
    "f(x) = \\underset{c}{\\mathrm{argmin}} \\ \\mathbb{E}\\left[(Y - c)^2 | X = x\\right].\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb011b85",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since the expectation is the value that minimizes the expectation of the squared deviations (see [Appendix: Elements of Probability Theory](appendix_elements_of_probability_theory.ipynb)), the optimal solution is \n",
    "\n",
    "\\begin{equation}\n",
    "f(x) = \\mathbb{E}(Y | X = x)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15247080",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In other words:\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Theorem</b>\n",
    "    \n",
    "The best prediction of the output for any input is the conditional expectation, when best is measured by the average squared error and the optimum is looked for over all possible functions of $x$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2e439a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> ***Question (optional)***\n",
    "> - What is the statistic giving the solution minimizing the EPE if we use the absolute error loss $|Y - f(X)|$ instead of the squared error loss?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7005fab6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "- [James, G., Witten, D., Hastie, T., Tibshirani, R., n.d. *An Introduction to Statistical Learning*, 2st ed. Springer, New York, NY.](https://www.statlearning.com/)\n",
    "- Chap. 2, 3 and 7 in [Hastie, T., Tibshirani, R., Friedman, J., 2009. *The Elements of Statistical Learning*, 2nd ed. Springer, New York.](https://doi.org/10.1007/978-0-387-84858-7)\n",
    "- Chap. 5 and 7 in [Wilks, D.S., 2019. *Statistical Methods in the Atmospheric Sciences*, 4th ed. Elsevier, Amsterdam.](https://doi.org/10.1016/C2017-0-03921-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e186998",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "***\n",
    "## Credit\n",
    "\n",
    "[//]: # \"This notebook is part of [E4C Interdisciplinary Center - Education](https://gitlab.in2p3.fr/energy4climate/public/education).\"\n",
    "Contributors include Bruno Deremble and Alexis Tantet.\n",
    "Several slides and images are taken from the very good [Scikit-learn course](https://inria.github.io/scikit-learn-mooc/).\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"display: flex; height: 70px\">\n",
    "    \n",
    "<img alt=\"Logo LMD\" src=\"images/logos/logo_lmd.jpg\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo IPSL\" src=\"images/logos/logo_ipsl.png\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo E4C\" src=\"images/logos/logo_e4c_final.png\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo EP\" src=\"images/logos/logo_ep.png\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo SU\" src=\"images/logos/logo_su.png\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo ENS\" src=\"images/logos/logo_ens.jpg\" style=\"display: inline-block\"/>\n",
    "\n",
    "<img alt=\"Logo CNRS\" src=\"images/logos/logo_cnrs.png\" style=\"display: inline-block\"/>\n",
    "    \n",
    "</div>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<div style=\"display: flex\">\n",
    "    <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0; margin-right: 10px\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a>\n",
    "    <br>This work is licensed under a &nbsp; <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": false,
   "autoclose": true,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
